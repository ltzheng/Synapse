<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8" />
  <meta name="description"
        content="Synapse: Trajectory-as-Exemplar Prompting with Memory for Computer Control.">
  <meta name="keywords" content="Synapse, Agent, Large Language Models, Computer Control, Web Navigation" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Synapse: Trajectory-as-Exemplar Prompting with Memory for Computer Control</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <!--TWITTER-->
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:title" content="Synapse: Trajectory-as-Exemplar Prompting with Memory for Computer Control">
  <meta name="twitter:description"
        content="Synapse: Trajectory-as-Exemplar Prompting with Memory for Computer Control">
  <meta name="twitter:image" content="https://github.com/ltzheng/Synapse/blob/main/assets/overview.png">

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/logo.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-widescreen">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <img src="./static/images/logo.png" style="width: 300px; height: auto;" alt="logo figure">
          <h1 class="title is-1 publication-title">Synapse: Trajectory-as-Exemplar Prompting<br>with Memory for Computer Control</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://ltzheng.github.io/">Longtao Zheng</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=JEVpgE8AAAAJ&hl=en">Rundong Wang</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=ROANfPUAAAAJ&hl=en">Xinrun Wang</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://personal.ntu.edu.sg/boan/index.html">Bo An</a><sup>1</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Nanyang Technological University</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- arXiv Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2306.07863"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/ltzheng/Synapse"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Trajectories Link. -->
              <span class="link-block">
                <a href="https://drive.google.com/file/d/1CnM3GF4kTAMZkGFasSXZ4Z2n5eiV8M9Z/view?usp=sharing"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Trajectories</span>
                  </a>
            </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-widescreen">
      <div class="column is-centered has-text-centered is-10 is-offset-1" id="teaserVideos">
        <div class="columns is-centered is-variable is-0">
          <div class="column" style="position:relative; width:100%; padding:0px; font-size:0em">
            <video class="video" controls autoplay playsinline muted loop>
              <source src="./static/videos/miniwob.mp4" type="video/mp4">
            </video>
          </div>
          <div class="column" style="position:relative; width:100%; padding:0px; font-size:0em">
            <video class="video" controls autoplay playsinline muted loop>
              <source src="./static/videos/united_0.mp4" type="video/mp4">
            </video>
          </div>
          <div class="column" style="position:relative; width:100%; padding:0px; font-size:0em">
            <video class="video" controls autoplay playsinline muted loop>
              <source src="./static/videos/twitter_0.mp4" type="video/mp4">
            </video>
          </div>
        </div>
      </div>
      <h2 class="subtitle has-text-centered">
        Synapse is a state-of-the-art LLM-powered computer agent in both MiniWoB++ and Mind2Web.
      </h2>
  </div>
</section>

<section class="section">
  <div class="container is-max-widescreen">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Building agents with large language models (LLMs) for computer control is a burgeoning research area, where the agent receives computer states and performs actions to complete complex tasks. Previous computer agents have demonstrated the benefits of in-context learning (ICL); however, their performance is hindered by several issues. First, the limited context length of LLMs and complex computer states restrict the number of exemplars, as a single webpage can consume the entire context. Second, the exemplars in current methods, such as high-level plans and multi-choice questions, cannot represent complete trajectories, leading to suboptimal performance in long-horizon tasks. Third, existing computer agents rely on task-specific exemplars and overlook the similarity among tasks, resulting in poor generalization to novel tasks. To address these challenges, we introduce Synapse, a computer agent featuring three key components: i) state abstraction, which filters out task-irrelevant information from raw states, allowing more exemplars within the limited context, ii) trajectory-as-exemplar prompting, which prompts the LLM with complete trajectories of the abstracted states and actions for improved multi-step decision-making, and iii) exemplar memory, which stores the embeddings of exemplars and retrieves them via similarity search for generalization to novel tasks. We evaluate Synapse on MiniWoB++, a standard task suite, and Mind2Web, a real-world website benchmark. In MiniWoB++, Synapse achieves a 99.2% average success rate (a 10% relative improvement) across 64 tasks using demonstrations from only 48 tasks. Notably, Synapse is the first ICL method to solve the book-flight task in MiniWoB++. Synapse also exhibits a 56% relative improvement in average step success rate over the previous state-of-the-art prompting scheme in Mind2Web.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3">Overview</h2>
    <figure>
      <a>
          <div style="text-align: center;">
          <img class="centered" src="./static/images/overview.png">
          </div>
      </a>
      <p class="caption">
          <b>Synapse consists of three main components. The process begins with state abstraction, where raw computer states (e.g., the HTML of webpages) are processed into concise task-relevant observations via few-shot learning of the LLM. This step reduces the number of tokens needed for each state, a prerequisite for the second component: trajectory-as-exemplar (TaE) prompting. In TaE prompting, the LLM is prompted with exemplary trajectories (a sequence of abstracted states and actions) and the current history to determine the next action. These prompts are retrieved from the exemplar memory using similarity search. The retrieval process utilizes the embeddings of task metadata, with each metadata mapped to the corresponding exemplars.<br>
    </figure>
    <br>
    <figure>
      <a>
          <div style="text-align: center;">
          <img class="centered" src="./static/images/trajectory_prompt.png">
          </div>
      </a>
      <p class="caption">
          <b>Comparison of trajectory-as-exemplar prompting with other prompting schemes. The illustration is based on the terminal task in MiniWoB++, where the agent is asked to delete a file ending with a specific extension. To solve this task, RCI (Kim et al., 2023) prompts the LLM with a step-by-step plan combined with the current state and the previous actions to generate each action, while MindAct (Deng et al., 2023) prompts the LLM with MCQ-formatted exemplars at each step. In contrast, Synapse uses a straightforward prompting scheme based on trajectory-level exemplars. This exemplar structure offers a consistent and interactive format, is more informative, and enables the LLM to produce temporally abstracted actions until a new state is required. As shown above, the LLM generates two consecutive actions: type(ls) and press(enter) without querying the new state. After executing these actions, it pauses to receive the new state for subsequent actions.<br>
    </figure>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3">Results</h2>
    <figure>
      <a>
          <div style="text-align: center;">
          <img class="centered" src="./static/images/miniwob_box_plot.png">
          </div>
      </a>
      <p class="caption">
          Synapse is the first ICL method that achieves human-level performance in MiniWoB++. It outperforms previous self-correction methods, including RCI and AdaPlanner. *Pix2Act and AdaPlanner are concurrent with our work. The outlier tasks are determined with an interquartile range of 1.5.<br>
    </figure>
    <br>
    <div class="columns is-centered">
      <div class="column">
        <div class="content">
          <h2 class="title is-4">Synapse vs Human</h2>
          <figure>
            <a>
                <div style="text-align: center;">
                <img class="centered" src="./static/images/performance_human.png">
                </div>
            </a>
          </figure>
        </div>
      </div>
      <div class="column">
        <div class="content">
          <h2 class="title is-4">Synapse vs BC+RL SotA</h2>
          <figure>
            <a>
                <div style="text-align: center;">
                <img class="centered" src="./static/images/performance_ccnet.png">
                </div>
            </a>
          </figure>
        </div>
      </div>
    </div>
    <div class="columns is-centered">
      <div class="column">
        <div class="content">
          <h2 class="title is-4">Synapse vs ICL SotA</h2>
          <figure>
            <a>
                <div style="text-align: center;">
                <img class="centered" src="./static/images/performance_rci.png">
                </div>
            </a>
          </figure>
        </div>
      </div>
      <div class="column">
        <div class="content">
          <h2 class="title is-4">Synapse vs Fine-tuning SotA</h2>
          <figure>
            <a>
                <div style="text-align: center;">
                <img class="centered" src="./static/images/performance_webgum.png">
                </div>
            </a>
          </figure>
        </div>
      </div>
    </div>
    <br>
    <figure>
      <p class="caption">
          Mind2Web results and ablations with CodeLlama-7B (top) and GPT-3.5 (bottom). We gradually add state abstraction, TaE prompting, and memory to demonstrate the effectiveness of each component. In Synapse w/ state abstraction, we simply use direct generation with fewer top-ranked elements in clean observations, outperforming the MCQ-formatted prompting used in MindAct. Synapse w/ state abstraction + TaE further shows the benefits of using trajectories as exemplars. In both these variants, we use static few-shot exemplars. Finally, we encode the training set as memory and retrieve exemplars via similarity search, which further improves performance.<br>
      <a>
          <div style="text-align: center;">
          <img class="centered" src="./static/images/mind2web.png">
          </div>
      </a>
    </figure>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3">Acknowledgement</h2>
    <br>
    We would like to thank the OpenAI Researcher Access Program for granting us API access for this project. We also thank the anonymous reviewers for their valuable feedback.
  </div>
</section>

<section class="section" id="BibTex">
  <div class="container is-max-desktop content">
    <h2 class="title">Citation</h2>
    <pre><code>@article{zheng2023synapse,
  title={Synapse: Trajectory-as-Exemplar Prompting with Memory for Computer Control},
  author={Zheng, Longtao and Wang, Rundong and Wang, Xinrun and An, Bo},
  journal={arXiv preprint arXiv:2306.07863},
  year={2023}
}</code></pre>
  </div>
</section>

<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer. The design of this website is based on <a href="https://nerfies.github.io/">NERFies</a>.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>